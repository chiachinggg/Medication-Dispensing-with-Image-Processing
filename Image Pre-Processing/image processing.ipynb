{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a1972f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from skimage import io, filters, transform\n",
    "\n",
    "def threshold_images(input_folder, output_folder, max_width, max_height, threshold_value):\n",
    "\n",
    "    # Create output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Loop through each file in the input folder\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith('.png'):\n",
    "            # Read the image\n",
    "            img_path = os.path.join(input_folder, filename)\n",
    "            image = io.imread(img_path, as_gray=True)\n",
    "\n",
    "            # Resize the image\n",
    "            # Calculate the scaling factor to fit within the specified range\n",
    "            scale_factor = min(max_width / image.shape[1], max_height / image.shape[0])\n",
    "            resized_image = transform.resize(image, (int(image.shape[0] * scale_factor), int(image.shape[1] * scale_factor)))\n",
    "\n",
    "            # Sharpening (using unsharp masking)\n",
    "            sharpened_image = filters.unsharp_mask(resized_image, radius=3, amount=3)\n",
    "            \n",
    "            # Apply thresholding\n",
    "            thresholded_image = sharpened_image > threshold_value\n",
    "\n",
    "            # Sharpening (using unsharp masking)\n",
    "            sharpened_image = filters.unsharp_mask(thresholded_image, radius=1, amount=1)\n",
    "            \n",
    "            # Save thresholded image to output folder\n",
    "            output_path = os.path.join(output_folder, filename)\n",
    "            io.imsave(output_path, sharpened_image.astype('uint8') * 255)  # Convert boolean array to uint8\n",
    "\n",
    "\n",
    "#input test\n",
    "# input_folder = 'C:/Users/jieru/Downloads/FIT3164/project/Medication-Dispensing-with-Image-Processing/image processing/x'\n",
    "# output_folder = \"C:/Users/jieru/Downloads/FIT3164/project/Medication-Dispensing-with-Image-Processing/image processing/enhanced_images\"\n",
    "\n",
    "input_folder = 'D:/2024/FYP/DATASETS/mydispense_meds/mydispense_meds/testing images'\n",
    "output_folder = 'D:/2024/FYP/DATASETS/mydispense_meds/processed_images'\n",
    "\n",
    "#actual folder\n",
    "# input_folder = 'C:/Users/jieru/Downloads/FIT3164/project/Medication-Dispensing-with-Image-Processing/image processing/mydispense_meds_proceessing'\n",
    "# output_folder = 'C:/Users/jieru/Downloads/FIT3164/project/Medication-Dispensing-with-Image-Processing/image processing/resized_images'\n",
    "max_width = 600  # Specify your maximum width\n",
    "max_height = 600  # Specify your maximum height\n",
    "threshold_value=0.76 #0.76\n",
    "\n",
    "# Apply try_all_threshold to PNG images in the input folder\n",
    "threshold_images(input_folder, output_folder, max_width, max_height, threshold_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e035daa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6384594",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" i really hate this \"\"\"\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# define input shape, required?\n",
    "\n",
    "def backbone(input_shape):\n",
    "    # we use a bunch of CNN, which may need to be refined later\n",
    "    input_img = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(input_img)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    # Additional layers can be added as needed\n",
    "    return models.Model(input_img, x)\n",
    "\n",
    "def feature_giant(bbmodel):\n",
    "    input_features = bbmodel.output\n",
    "    # upsample\n",
    "    x = layers.Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same', activation='relu')(input_features)\n",
    "    x = layers.Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2DTranspose(32, (3, 3), strides=(2, 2), padding='same', activation='relu')(x)\n",
    "    return models.Model(bbmodel.input, x)\n",
    "\n",
    "# prediction maps\n",
    "def prediction_maps(feature_giant_model):\n",
    "    input_img = feature_giant_model.input\n",
    "    features = feature_giant_model.output\n",
    "\n",
    "    # Predicted probability map (binary classification)\n",
    "    prob_map = layers.Conv2D(1, (1, 1), activation='sigmoid', name='prob_map')(features)\n",
    "    \n",
    "    # Predicted threshold map\n",
    "    threshold_map = layers.Conv2D(1, (1, 1), activation='sigmoid', name='threshold_map')(features)\n",
    "    \n",
    "    return models.Model(input_img, [prob_map, threshold_map])\n",
    "\n",
    "def approx_binarization(prob, threshold):\n",
    "    binarized_map = tf.keras.backend.greater_equal(prob_map, threshold_map)\n",
    "    return binarized_map\n",
    "\n",
    "def binmodel(shape):\n",
    "    # Create the backbone and feature giant models\n",
    "    backbone_model = backbone(input_shape)\n",
    "    feature_giant_model = feature_giant(backbone_model)\n",
    "    \n",
    "    # Create the prediction maps model\n",
    "    prediction_maps_model = prediction_maps(feature_giant_model)\n",
    "    \n",
    "    # Define the input and outputs\n",
    "    input_img = prediction_maps_model.input\n",
    "    prob_map, threshold_map = prediction_maps_model.output\n",
    "    \n",
    "    # Calculate the binarized map\n",
    "    binarized_map = approx_binarization(prob_map, threshold_map)\n",
    "    \n",
    "    # Create the final model\n",
    "    return models.Model(input_img, [prob_map, threshold_map, binarized_map])\n",
    "\n",
    "input_shape = (128, 128, 3)  # Adjust input shape as needed\n",
    "model = binmodel(input_shape)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss={'prob_map': 'binary_crossentropy',\n",
    "                                      'threshold_map': 'mse',\n",
    "                                      'binarized_map': 'binary_crossentropy'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0874f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bounding():\n",
    "    ''' dbnet algorithm used, with this hopefully we can by pass the binarization problem '''\n",
    "    pass\n",
    "\n",
    "def meat():\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
